Script started on Thu Nov 23 07:23:00 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700752980
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 5, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:23:13 2023
Script started on Thu Nov 23 07:23:13 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700752993
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 5, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:23:26 2023
Script started on Thu Nov 23 07:23:26 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753006
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 4, 7, 3, 5, 1 and 10.[0m

Script done on Thu Nov 23 07:23:38 2023
Script started on Thu Nov 23 07:23:38 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753018
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 4, 5, 1 and 10[0m

Script done on Thu Nov 23 07:23:53 2023
Script started on Thu Nov 23 07:23:53 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753033
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 9, 2, 4, 7, and 10.[0m
> [1m[32m[0m

Script done on Thu Nov 23 07:24:09 2023
Script started on Thu Nov 23 07:24:09 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753049
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 5, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:24:22 2023
Script started on Thu Nov 23 07:24:22 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753062
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 9, 2, 7, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:24:34 2023
Script started on Thu Nov 23 07:24:34 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753074
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are:  2,4,8,9,10[0m

Script done on Thu Nov 23 07:24:44 2023
Script started on Thu Nov 23 07:24:44 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753084
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0m3, 7, 9, 2, 4, 6, 8, 5, 1[0m

Script done on Thu Nov 23 07:24:55 2023
Script started on Thu Nov 23 07:24:55 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753095
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 4, 7, 9, 2, 1 and 10.[0m

Script done on Thu Nov 23 07:25:06 2023
Script started on Thu Nov 23 07:25:06 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753106
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 5, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:25:18 2023
Script started on Thu Nov 23 07:25:18 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753118
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 4, 7, 3, 5, 1 and 10.[0m

Script done on Thu Nov 23 07:25:30 2023
Script started on Thu Nov 23 07:25:30 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753130
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 4, 7, 3, 5, 1 and 10.[0m

Script done on Thu Nov 23 07:25:42 2023
Script started on Thu Nov 23 07:25:42 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753142
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 4, 2, 7, 3, 9, 5, 1 and 10.[0m

Script done on Thu Nov 23 07:25:54 2023
Script started on Thu Nov 23 07:25:54 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753154
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 4, 7, 9, 2, 1 and 10.[0m
> [1m[32m[0m

Script done on Thu Nov 23 07:26:53 2023
Script started on Thu Nov 23 07:26:53 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753213
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 7, 3, 5, 4, 1 and 10.[0m

Script done on Thu Nov 23 07:27:05 2023
Script started on Thu Nov 23 07:27:05 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753225
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 4, 7, 9, 2, 1 and 10.[0m

Script done on Thu Nov 23 07:27:19 2023
Script started on Thu Nov 23 07:27:19 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753239
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are:  3,749,258,620,589,504,355,610,952,582 and 985,654.[0m

Script done on Thu Nov 23 07:27:32 2023
Script started on Thu Nov 23 07:27:32 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753252
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 3, 5, 9, 2, 4, 7, and 10.[0m

Script done on Thu Nov 23 07:27:44 2023
Script started on Thu Nov 23 07:27:44 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700753264
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
[33m
> [1m[32m[0mThe randomly picked numbers are: 6, 8, 9, 2, 4, 7, 3, 5, 1 and 10.[0m

Script done on Thu Nov 23 07:27:55 2023
Script started on Thu Nov 23 13:55:20 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776520
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .......^C
Script done on Thu Nov 23 13:55:21 2023
Script started on Thu Nov 23 13:55:21 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776521
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .........................^C
Script done on Thu Nov 23 13:55:22 2023
Script started on Thu Nov 23 13:55:22 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776522
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
^C
Script done on Thu Nov 23 13:55:30 2023
Script started on Thu Nov 23 13:55:30 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776530
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ..........^C
Script done on Thu Nov 23 13:55:30 2023
Script started on Thu Nov 23 13:55:30 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776530
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ............^C
Script done on Thu Nov 23 13:55:31 2023
Script started on Thu Nov 23 13:55:31 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776531
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ............^C
Script done on Thu Nov 23 13:55:31 2023
Script started on Thu Nov 23 13:55:31 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776531
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ..........^C
Script done on Thu Nov 23 13:55:31 2023
Script started on Thu Nov 23 13:55:31 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776531
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .........^C
Script done on Thu Nov 23 13:55:31 2023
Script started on Thu Nov 23 13:55:31 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776531
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ........^C
Script done on Thu Nov 23 13:55:32 2023
Script started on Thu Nov 23 13:55:32 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776532
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ........................^C
Script done on Thu Nov 23 13:55:32 2023
Script started on Thu Nov 23 13:55:32 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776532
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ..............................ㅊ...... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 4 / 8 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
main: interactive mode on.
sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


0== Running in chat mode. ==
 - Press Ctrl+C to interject at any time.
 - Press Return to return control to LLaMA.
 - If you want to submit another line, end your input in '\'.
^C
Script done on Thu Nov 23 13:55:35 2023
Script started on Thu Nov 23 13:55:35 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776535
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ....^C
Script done on Thu Nov 23 13:55:35 2023
Script started on Thu Nov 23 13:55:35 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776535
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: .......^C
Script done on Thu Nov 23 13:55:35 2023
Script started on Thu Nov 23 13:55:35 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776535
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ........^C
Script done on Thu Nov 23 13:55:36 2023
Script started on Thu Nov 23 13:55:36 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776536
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ........^C
Script done on Thu Nov 23 13:55:36 2023
Script started on Thu Nov 23 13:55:36 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776536
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ........^C
Script done on Thu Nov 23 13:55:36 2023
Script started on Thu Nov 23 13:55:36 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
main: seed = 1700776536
llama_model_load: loading model from 'ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from 'ggml-alpaca-7b-q4.bin'
llama_model_load: ............^C
Script done on Thu Nov 23 13:55:37 2023
Script started on Thu Nov 23 13:55:37 2023
command: bash -c echo -e "Pick ten random numbers from 1-10.\n" | ./chat_mac | awk '/def/{exit}1' | awk '/import/{exit}1'
